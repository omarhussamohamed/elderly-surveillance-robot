{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Notebook\n",
    "\n",
    "This notebook documents **experimental work** conducted during the development of the **Elderly Monitoring AI System**.\n",
    "\n",
    "⚠️ **Important**  \n",
    "- This notebook is for **research and validation only**.  \n",
    "- It is **NOT part of the final runtime pipeline**.  \n",
    "- The production-ready logic used by the system is implemented in `/src/layers/fall_detection`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall Detection Experiment (MediaPipe Pose)\n",
    "\n",
    "This notebook explores a **vision-based fall detection approach** using **MediaPipe Pose Landmarker (Live Stream mode)**.\n",
    "\n",
    "The experiment focuses on:\n",
    "- body orientation\n",
    "- vertical motion velocity\n",
    "- temporal confirmation\n",
    "\n",
    "Insights from this experiment informed the simplified and safer fall detection logic used in the final system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "- Detect potential falls from live video input\n",
    "- Analyze pose orientation and motion patterns\n",
    "- Evaluate temporal stability before raising fall alerts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "- Python 3.10\n",
    "- OpenCV\n",
    "- MediaPipe (Pose Landmarker Tasks API)\n",
    "- NumPy\n",
    "\n",
    "See `requirements-experiments.txt` for the full dependency list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "This experiment uses the **MediaPipe Pose Landmarker** in **LIVE_STREAM** mode.\n",
    "\n",
    "⚠️ The required model file must be placed locally:\n",
    "\n",
    "```\n",
    "pose_landmarker_full.task\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "print(\"✅ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MODEL SETUP\n",
    "# =========================\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path=\"pose_landmarker_full.task\")\n",
    "current_result = None\n",
    "\n",
    "def result_callback(result, output_image, timestamp):\n",
    "    global current_result\n",
    "    current_result = result\n",
    "\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=vision.RunningMode.LIVE_STREAM,\n",
    "    num_poses=1,\n",
    "    min_pose_detection_confidence=0.5,\n",
    "    result_callback=result_callback\n",
    ")\n",
    "\n",
    "landmarker = vision.PoseLandmarker.create_from_options(options)\n",
    "print(\"✅ Pose landmarker initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# VIDEO SETUP\n",
    "# =========================\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "output_path = \"clean_fall_monitor.mp4\"\n",
    "out = cv2.VideoWriter(\n",
    "    output_path,\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "    fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "print(\"✅ Video stream initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FALL DETECTION LOGIC VARIABLES\n",
    "# =========================\n",
    "\n",
    "frame_count = 0\n",
    "center_history = deque(maxlen=15)\n",
    "angle_history = deque(maxlen=10)\n",
    "fall_state = \"NORMAL\"\n",
    "fall_start_time = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_overlay(img, status):\n",
    "    \"\"\"Draws a clean status overlay.\"\"\"\n",
    "    overlay = img.copy()\n",
    "    color = (80, 175, 76) if status == \"NORMAL\" else (50, 50, 200)\n",
    "    label = \"SYSTEM: NORMAL\" if status == \"NORMAL\" else \"ALERT: FALL DETECTED\"\n",
    "\n",
    "    cv2.rectangle(overlay, (0, 0), (img.shape[1], 50), color, -1)\n",
    "    cv2.addWeighted(overlay, 0.6, img, 0.4, 0, img)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    text_size = cv2.getTextSize(label, font, 0.7, 1)[0]\n",
    "    text_x = (img.shape[1] - text_size[0]) // 2\n",
    "    cv2.putText(img, label, (text_x, 32), font, 0.7, (255, 255, 255), 1, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MAIN LOOP\n",
    "# =========================\n",
    "\n",
    "print(\"Starting fall detection experiment — press ESC to exit\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    timestamp_ms = int(frame_count * (1000 / fps))\n",
    "    frame_count += 1\n",
    "\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "    landmarker.detect_async(mp_image, timestamp_ms)\n",
    "    current_time = time.time()\n",
    "\n",
    "    if current_result and current_result.pose_landmarks:\n",
    "        landmarks = current_result.pose_landmarks[0]\n",
    "\n",
    "        mid_hip_y = (landmarks[23].y + landmarks[24].y) / 2\n",
    "        center_history.append((mid_hip_y * frame_height, timestamp_ms))\n",
    "\n",
    "        dx = ((landmarks[23].x + landmarks[24].x)/2) - ((landmarks[11].x + landmarks[12].x)/2)\n",
    "        dy = ((landmarks[23].y + landmarks[24].y)/2) - ((landmarks[11].y + landmarks[12].y)/2)\n",
    "        avg_angle = abs(90 - abs(math.degrees(math.atan2(dy, dx))))\n",
    "\n",
    "        velocity = 0\n",
    "        if len(center_history) >= 2:\n",
    "            (y2, t2), (y1, t1) = center_history[-1], center_history[-2]\n",
    "            dt = max((t2 - t1) / 1000.0, 1e-6)\n",
    "            velocity = (y2 - y1) / dt\n",
    "\n",
    "        if fall_state == \"NORMAL\" and velocity > 400 and avg_angle > 45:\n",
    "            fall_state = \"FALLING\"\n",
    "            fall_start_time = current_time\n",
    "        elif fall_state == \"FALLING\" and (current_time - fall_start_time > 0.3):\n",
    "            fall_state = \"FALL\"\n",
    "        elif fall_state == \"FALL\" and avg_angle < 30:\n",
    "            fall_state = \"NORMAL\"\n",
    "\n",
    "    draw_styled_overlay(frame, fall_state)\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Monitoring\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "landmarker.close()\n",
    "print(\"Experiment finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations & Notes\n",
    "\n",
    "- Rapid vertical motion combined with body orientation change is a strong fall indicator.\n",
    "- Temporal confirmation reduces false positives.\n",
    "- Lighting and camera angle affect stability.\n",
    "- This experiment motivated the simpler, frame-based fall detection logic used in the final system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment\n",
    "print(f\"OpenCV Version: {cv2.__version__}\")\n",
    "print(f\"MediaPipe Version: {mp.__version__}\")\n",
    "\n",
    "model_file = \"pose_landmarker_full.task\"\n",
    "if os.path.exists(model_file):\n",
    "    print(f\"✅ Model file '{model_file}' found.\")\n",
    "else:\n",
    "    print(f\"❌ Missing '{model_file}'. Download it from MediaPipe models page.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
